<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/">
  <channel>
    <title>Étienne&#39;s blog</title>
    <link>http://localhost:1313/</link>
    <description>Recent content on Étienne&#39;s blog</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <managingEditor>eti.andre@gmail.com (Étienne André)</managingEditor>
    <webMaster>eti.andre@gmail.com (Étienne André)</webMaster>
    <copyright>© 2024 Étienne André</copyright>
    <lastBuildDate>Sun, 01 Jan 2023 08:00:00 -0700</lastBuildDate>
    <atom:link href="http://localhost:1313/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Publications</title>
      <link>http://localhost:1313/publications/</link>
      <pubDate>Mon, 30 Sep 2024 10:09:33 +0200</pubDate><author>eti.andre@gmail.com (Étienne André)</author>
      <guid>http://localhost:1313/publications/</guid>
      <description>&lt;ul&gt;
&lt;li&gt;André, É., Fourer, D. &amp;amp; Schwarz, D. (2024). DJ Mix Transcription with Multi-Pass Non-Negative Matrix Factorization [Manuscript submitted for publication at ICASSP2025]&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://hal.science/hal-02401796v4/&#34;&gt;André, É., Dulong, R., Guermouche, A., &amp;amp; Trahay, F. (2022). DUF: Dynamic Uncore Frequency scaling to reduce power consumption. Concurrency and Computation: Practice and Experience, 34(3), e6580.&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;</description>
      <content:encoded><![CDATA[<ul>
<li>André, É., Fourer, D. &amp; Schwarz, D. (2024). DJ Mix Transcription with Multi-Pass Non-Negative Matrix Factorization [Manuscript submitted for publication at ICASSP2025]</li>
<li><a href="https://hal.science/hal-02401796v4/">André, É., Dulong, R., Guermouche, A., &amp; Trahay, F. (2022). DUF: Dynamic Uncore Frequency scaling to reduce power consumption. Concurrency and Computation: Practice and Experience, 34(3), e6580.</a></li>
</ul>
]]></content:encoded>
    </item>
    <item>
      <title>Resume</title>
      <link>http://localhost:1313/resume/</link>
      <pubDate>Mon, 30 Sep 2024 09:35:10 +0200</pubDate><author>eti.andre@gmail.com (Étienne André)</author>
      <guid>http://localhost:1313/resume/</guid>
      <description>&lt;h2 id=&#34;étienne-andré&#34;&gt;Étienne André&lt;/h2&gt;
&lt;p&gt;&lt;a href=&#34;mailto:eti.andre@gmail.com&#34;&gt;eti.andre@gmail.com&lt;/a&gt; / &lt;a href=&#34;tel:+33651236489&#34;&gt;(+33) 6 51 23 64 89&lt;/a&gt; / &lt;a href=&#34;https://etiand.re&#34;&gt;https://etiand.re&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;French &amp;amp; English spoken and written&lt;/p&gt;
&lt;h2 id=&#34;education&#34;&gt;Education&lt;/h2&gt;
&lt;h3 id=&#34;2023-2024--second-masters-degree&#34;&gt;2023-2024 / Second masters&amp;rsquo; degree&lt;/h3&gt;
&lt;p&gt;&lt;strong&gt;Signal Processing, Computer Science and Acoustics applied to Music (&lt;a href=&#34;http://www.atiam.ircam.fr/en/&#34;&gt;ATIAM&lt;/a&gt;)&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;em&gt;IRCAM / Sorbonne Université, France&lt;/em&gt;&lt;/p&gt;
&lt;h3 id=&#34;2016-2020--masters-degree&#34;&gt;2016-2020 / Masters&amp;rsquo; degree&lt;/h3&gt;
&lt;p&gt;&lt;strong&gt;Embedded systems (&lt;a href=&#34;https://www.telecom-sudparis.eu/en/formation/embedded-systems-mobility-and-communicating-objects/&#34;&gt;SEM&lt;/a&gt;)&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;em&gt;Télécom SudParis, France&lt;/em&gt;&lt;/p&gt;
&lt;h2 id=&#34;experience&#34;&gt;Experience&lt;/h2&gt;
&lt;h3 id=&#34;2024---internship--automatic-dj-mix-transcription&#34;&gt;2024 - Internship / Automatic DJ Mix Transcription&lt;/h3&gt;
&lt;p&gt;&lt;em&gt;IRCAM, ISMM, STMS, Paris, France&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;MIR, NMF, Python, CPU/GPU, Pytorch&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Design of an innovative DJ mix transcription algorithm.&lt;/li&gt;
&lt;li&gt;Submission of a &lt;a href=&#34;http://localhost:1313/publications&#34;&gt;scientific publication&lt;/a&gt;.&lt;/li&gt;
&lt;li&gt;Study of data sets.&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;2021---2023--dsp-and-embedded-engineer&#34;&gt;2021 - 2023 / DSP and embedded engineer&lt;/h3&gt;
&lt;p&gt;&lt;em&gt;Arkamys, Paris, France&lt;/em&gt;&lt;/p&gt;</description>
      <content:encoded><![CDATA[<h2 id="étienne-andré">Étienne André</h2>
<p><a href="mailto:eti.andre@gmail.com">eti.andre@gmail.com</a> / <a href="tel:+33651236489">(+33) 6 51 23 64 89</a> / <a href="https://etiand.re">https://etiand.re</a></p>
<p>French &amp; English spoken and written</p>
<h2 id="education">Education</h2>
<h3 id="2023-2024--second-masters-degree">2023-2024 / Second masters&rsquo; degree</h3>
<p><strong>Signal Processing, Computer Science and Acoustics applied to Music (<a href="http://www.atiam.ircam.fr/en/">ATIAM</a>)</strong></p>
<p><em>IRCAM / Sorbonne Université, France</em></p>
<h3 id="2016-2020--masters-degree">2016-2020 / Masters&rsquo; degree</h3>
<p><strong>Embedded systems (<a href="https://www.telecom-sudparis.eu/en/formation/embedded-systems-mobility-and-communicating-objects/">SEM</a>)</strong></p>
<p><em>Télécom SudParis, France</em></p>
<h2 id="experience">Experience</h2>
<h3 id="2024---internship--automatic-dj-mix-transcription">2024 - Internship / Automatic DJ Mix Transcription</h3>
<p><em>IRCAM, ISMM, STMS, Paris, France</em></p>
<p>MIR, NMF, Python, CPU/GPU, Pytorch</p>
<ul>
<li>Design of an innovative DJ mix transcription algorithm.</li>
<li>Submission of a <a href="/publications">scientific publication</a>.</li>
<li>Study of data sets.</li>
</ul>
<h3 id="2021---2023--dsp-and-embedded-engineer">2021 - 2023 / DSP and embedded engineer</h3>
<p><em>Arkamys, Paris, France</em></p>
<p>C, C++, Qt, Matlab, Python, Linux, DSP, GStreamer</p>
<ul>
<li>Development of an automatic tool for optimizing the automotive audio experience.</li>
<li>Development of complex multi-platform audio applications.</li>
<li>Development of Android applications.</li>
<li>Algorithm porting to DSP.</li>
<li>GStreamer pipeline design.</li>
<li>Embedded Linux development and deployment.</li>
</ul>
<h3 id="2020-internship--smartphone-audio-performance-evaluation">2020 Internship / smartphone audio performance evaluation</h3>
<p><em>DXOMark, Boulogne-Billancourt, France</em></p>
<p>Python, Qt, DSP, Android</p>
<ul>
<li>Design and implementation of an audio dynamic performance evaluation method for smartphones.</li>
<li>Automation and simplification of the audio test protocol through the creation of various scripts and graphical interfaces.</li>
</ul>
<h3 id="2019-internship--duf-dynamic-uncore-frequency">2019 Internship / DUF: Dynamic Uncore Frequency</h3>
<p><em>Télécom SudParis, Évry-Courcouronnes, France</em></p>
<p>C, Linux, distributed systems</p>
<ul>
<li>Development of a daemon dynamically adapting the uncore frequency on Intel architectures, in order to reduce the energy consumption of a distributed computing application.</li>
<li>Participation to a <a href="/publications">scientific publication</a>.</li>
</ul>
]]></content:encoded>
    </item>
    <item>
      <title>Introduction to DJ Mix Transcription</title>
      <link>http://localhost:1313/posts/dj-transcription/introduction/</link>
      <pubDate>Fri, 27 Sep 2024 09:58:24 +0200</pubDate><author>eti.andre@gmail.com (Étienne André)</author>
      <guid>http://localhost:1313/posts/dj-transcription/introduction/</guid>
      <description>&lt;p&gt;Transcribing a DJ mix involves analyzing the mix to extract the parameters and techniques used by DJs. This post explores the challenges in DJ mix reverse engineering, explaining key tasks such as alignment and unmixing, and why existing methods struggle to capture the full range of transformations in complex DJ sets.&lt;/p&gt;</description>
      <content:encoded><![CDATA[<p>Transcribing a DJ mix involves analyzing the mix to extract the parameters and techniques used by DJs. This post explores the challenges in DJ mix reverse engineering, explaining key tasks such as alignment and unmixing, and why existing methods struggle to capture the full range of transformations in complex DJ sets.</p>
]]></content:encoded>
    </item>
    <item>
      <title>Optical tracking of vinyl records</title>
      <link>http://localhost:1313/posts/dj-transcription/vinyl-optical-tracking/</link>
      <pubDate>Thu, 26 Sep 2024 14:48:48 +0200</pubDate><author>eti.andre@gmail.com (Étienne André)</author>
      <guid>http://localhost:1313/posts/dj-transcription/vinyl-optical-tracking/</guid>
      <description>&lt;p&gt;We implemented an optical tracking method to measure the angular velocity of a vinyl record during playback, enabling the extraction of the time-warping ground truth from a filmed DJ performance. The method can be especially useful given the vast amount of videos of DJ performances online. By tracking a reference picture of a vinyl record to each frame of a video of a DJ turntable, the record&amp;rsquo;s rotation speed can be estimated.&lt;/p&gt;</description>
      <content:encoded><![CDATA[<p>We implemented an optical tracking method to measure the angular velocity of a vinyl record during playback, enabling the extraction of the time-warping ground truth from a filmed DJ performance. The method can be especially useful given the vast amount of videos of DJ performances online. By tracking a reference picture of a vinyl record to each frame of a video of a DJ turntable, the record&rsquo;s rotation speed can be estimated.</p>
$$ 2+2 = 4 \frac{A}{B} $$<h2 id="tracking">Tracking</h2>
<p>The tracking is based on the scale-invariant feature transform (SIFT) algorithm @loweDistinctiveImageFeatures2004. The algorithm extracts keypoints from a reference image of the vinyl&rsquo;s label (@fig:vinyl-ref) and from each frame of a video of the vinyl being played. By matching these keypoints, a homography matrix is computed for each frame. This matrix represents the geometric transformation between the reference and the current frame, capturing the rotation, translation, and scale changes (@fig:vinyl-track). The sequence of homography matrices obtained across the frames is stored for further analysis.</p>
<figure><img src="/posts/dj-transcription/vinyl-optical-tracking/vinyl-ref.jpg"><figcaption>
      <h4>Reference image of the vinyl label.</h4>
    </figcaption>
</figure>

<video controls preload="auto" width="100%"  playsinline class="html-video">
    <source src="/posts/dj-transcription/vinyl-optical-tracking/out.mp4" type="video/mp4">
  <span>Your browser doesn't support embedded videos, but don't worry, you can <a href="/posts/dj-transcription/vinyl-optical-tracking/out.mp4">download it</a> and watch it with your favorite video player!</span>
</video>
<h2 id="extracting-the-rotation-angles-from-the-homography-matrix">Extracting the rotation angles from the homography matrix</h2>
<p>Each homography matrix</p>
<h2 id="rotation-computation">Rotation computation</h2>
<p>The stored homography matrices are then decomposed to extract the rotation angles of the vinyl record using the singular value decomposition method from #cite(<faugerasMOTIONSTRUCTUREMOTION1988>, form: &ldquo;prose&rdquo;) (section 7). The rotation on the $z$ axis corresponds to the rotation of the vinyl record. The rotation angle sequence is unwrapped then derived to obtain the rotation speed. Then, with knowledge of the nominal speed of the record (e.g. 33 or 45 rpm), the time-warping function can be calculated. Example results are illustrated in @fig:vinyl-results.</p>






<div class="highlight"><pre tabindex="0" style="color:#cdd6f4;background-color:#1e1e2e;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f849c"> 1</span><span><span style="color:#cba6f7">def</span> <span style="color:#89b4fa">decompose_homography</span>(M):
</span></span><span style="display:flex;"><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f849c"> 2</span><span>    <span style="color:#cba6f7">if</span> M <span style="color:#89dceb;font-weight:bold">is</span> <span style="color:#fab387">None</span>:
</span></span><span style="display:flex;"><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f849c"> 3</span><span>        <span style="color:#cba6f7">return</span> <span style="color:#fab387">0</span>, <span style="color:#fab387">0</span>, <span style="color:#fab387">0</span>
</span></span><span style="display:flex;"><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f849c"> 4</span><span>    r1 <span style="color:#89dceb;font-weight:bold">=</span> M[<span style="color:#fab387">0</span>:<span style="color:#fab387">3</span>, <span style="color:#fab387">0</span>]
</span></span><span style="display:flex;"><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f849c"> 5</span><span>    r2 <span style="color:#89dceb;font-weight:bold">=</span> M[<span style="color:#fab387">0</span>:<span style="color:#fab387">3</span>, <span style="color:#fab387">1</span>]
</span></span><span style="display:flex;"><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f849c"> 6</span><span>    r3 <span style="color:#89dceb;font-weight:bold">=</span> np<span style="color:#89dceb;font-weight:bold">.</span>cross(r1, r2)
</span></span><span style="display:flex;"><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f849c"> 7</span><span>    R <span style="color:#89dceb;font-weight:bold">=</span> np<span style="color:#89dceb;font-weight:bold">.</span>column_stack((r1, r2, r3))
</span></span><span style="display:flex;"><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f849c"> 8</span><span>
</span></span><span style="display:flex;"><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f849c"> 9</span><span>    U, S, Vt <span style="color:#89dceb;font-weight:bold">=</span> np<span style="color:#89dceb;font-weight:bold">.</span>linalg<span style="color:#89dceb;font-weight:bold">.</span>svd(R)
</span></span><span style="display:flex;"><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f849c">10</span><span>    R <span style="color:#89dceb;font-weight:bold">=</span> np<span style="color:#89dceb;font-weight:bold">.</span>dot(U, Vt)
</span></span><span style="display:flex;"><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f849c">11</span><span>
</span></span><span style="display:flex;"><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f849c">12</span><span>    theta_x <span style="color:#89dceb;font-weight:bold">=</span> np<span style="color:#89dceb;font-weight:bold">.</span>arctan2(R[<span style="color:#fab387">2</span>, <span style="color:#fab387">1</span>], R[<span style="color:#fab387">2</span>, <span style="color:#fab387">2</span>])
</span></span><span style="display:flex;"><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f849c">13</span><span>    theta_y <span style="color:#89dceb;font-weight:bold">=</span> np<span style="color:#89dceb;font-weight:bold">.</span>arctan2(<span style="color:#89dceb;font-weight:bold">-</span>R[<span style="color:#fab387">2</span>, <span style="color:#fab387">0</span>], np<span style="color:#89dceb;font-weight:bold">.</span>sqrt(R[<span style="color:#fab387">2</span>, <span style="color:#fab387">1</span>] <span style="color:#89dceb;font-weight:bold">**</span> <span style="color:#fab387">2</span> <span style="color:#89dceb;font-weight:bold">+</span> R[<span style="color:#fab387">2</span>, <span style="color:#fab387">2</span>] <span style="color:#89dceb;font-weight:bold">**</span> <span style="color:#fab387">2</span>))
</span></span><span style="display:flex;"><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f849c">14</span><span>    theta_z <span style="color:#89dceb;font-weight:bold">=</span> np<span style="color:#89dceb;font-weight:bold">.</span>arctan2(R[<span style="color:#fab387">1</span>, <span style="color:#fab387">0</span>], R[<span style="color:#fab387">0</span>, <span style="color:#fab387">0</span>])
</span></span><span style="display:flex;"><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f849c">15</span><span>
</span></span><span style="display:flex;"><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f849c">16</span><span>    <span style="color:#cba6f7">return</span> theta_x, theta_y, theta_z</span></span></code></pre></div>
<p>Given a homography matrix \( \mathbf{M} \), we can decompose it to retrieve the rotation matrix \( \mathbf{R} \) using the following steps:</p>
<ol>
<li>
<p>Assume \( \mathbf{M} \) can be expressed as:
</p>
\[
   \mathbf{M} = \begin{bmatrix}
   \mathbf{r}_1 & \mathbf{r}_2 & \mathbf{t} \\
   \end{bmatrix}
   \]<p>
where \( \mathbf{r}_1 \) and \( \mathbf{r}_2 \) are the first two columns of the rotation matrix \( \mathbf{R} \), and \( \mathbf{t} \) is the translation component.</p>
</li>
<li>
<p>Compute the third column \( r_3 \) of the rotation matrix as the cross product:
</p>
\[
   r_3 = r_1 \times r_2
   \]</li>
<li>
<p>Form the estimated rotation matrix:
</p>
\[
   \mathbf{R} = \begin{bmatrix}
   r_1 & r_2 & r_3 \\
   \end{bmatrix}
   \]</li>
<li>
<p>Perform Singular Value Decomposition (SVD) on \( \mathbf{R} \):
</p>
\[
   \mathbf{R} = \mathbf{U} \mathbf{S} \mathbf{V}^T
   \]</li>
<li>
<p>Correct \( \mathbf{R} \) to enforce orthonormality:
</p>
\[
   \mathbf{R} = \mathbf{U} \mathbf{V}^T
   \]</li>
<li>
<p>Extract the Euler angles \( (\theta_x, \theta_y, \theta_z) \) from the rotation matrix \( \mathbf{R} \):
</p>
\[
   \theta_x = \arctan2(R[2, 1], R[2, 2])
   \]\[
   \theta_y = \arctan2(-R[2, 0], \sqrt{R[2, 1]^2 + R[2, 2]^2})
   \]\[
   \theta_z = \arctan2(R[1, 0], R[0, 0])
   \]</li>
</ol>
<p>The angles \( \theta_x \), \( \theta_y \), \( \theta_z \) represent the rotation around the respective axes and allow us to retrieve the 3D rotations embedded within the homography transformation.</p>
<figure><img src="/posts/dj-transcription/vinyl-optical-tracking/rotato.svg"><figcaption>
      <h4>Computed angle and rotation speed of the vinyl. In the experiment, the record was played at 33 rpm for the first 30 seconds, then was &#34;scratched&#34; by hand for the remaining of the experiment.</h4>
    </figcaption>
</figure>

<p>The accuracy of the extracted rotational speed is directly dependent on the temporal resolution of the video (usually 30 or 60 images per second), which limits the granularity of the measurements. Additionally, the method is susceptible to noise introduced by the tracking process, which can affect the precision of the rotation and speed calculations.</p>
<p>Similar object tracking techniques could be used to extract ground truth data from any visible physical control of the DJ equipment.</p>
]]></content:encoded>
    </item>
  </channel>
</rss>
